# Introduction Course in Machine Learning (2ST129) at Uppsala University 

Welcome to the GitHub repo for the introduction course in Introduction to Machine Learning at Uppsala University. This repo contains all necessary material and information for the course.

## Course Background 
The course is given to second-year master students in the Statistics masters program. 

## Expected workload
The course takes roughly 20h per week. In total the course should take roughly 200h. If the student aims for VG more time might be needed. 

## Prerequisites and Course Goals
See course syllabus [here](https://www.uu.se/en/admissions/freestanding-courses/course/?kKod=2ST129&typ=1).

Roughly the course assumes basic knowledge in linear algebra, calculus, probability theory and programming (with R or Python).

## (Rough) Course Plan
You can find a rough course plan with reading instructions [here](https://docs.google.com/spreadsheets/d/1HC_QN2mCq9bkCPzmkP8RaR3RokFQCWo9oPuU7rFyR8Y/edit?usp=sharing).

## Schedule
You can find the course schedule on TimeEdit [here](https://cloud.timeedit.net/uu/web/schema/) (search for course code 2ST129).

## Grading
The course is graded with U (Underkänd/Fail), G (Godkänd/Pass), VG (väl godkänd/Pass with distinction).

To pass, you should pass all assignments and the mini-project. 

To get the grade VG on the course, a total of 7 or more VG points is needed. Each assignment has an additional task to complete to get VG on the assignment (and one VG-point). If the final mini-project gets VG, the students are awarded 2 VG points for the mini-project. VG-points will only be awarded on the first deadline of the assignment.

Note that aiming for VG might mean that you need to put in more hours than the expected 20h per week. 

### Reassessing grades
Grades are not subject to appeal. However, a grading decision must be reassessed if it is clearly incorrect. Grades can never be lowered. If students want grades to be reassessed, they should contact the course administration who will distribute a form for reassessment the students have to fill out. 

### Re-taking the course
If you fail or drop-out from the course you will need to re-take all assignments and redo the mini-project next time the course is given.

## Course Literature and Video Material
Below are the main references for the course. All books are available free online. Some articles may need access from an Uppsala University network.

### Literature

- BB: Bishop and Bishop. Deep learning - Foundations and Concepts. MIT Press, 2024. [online access](https://www.bishopbook.com/)
- ESL: Hastie, Trevor, Tibshirani, Robert, and Friedman, Jerome. The elements of statistical learning: data mining, inference, and prediction. 2nd Edition. Springer Science & Business Media, 2009. [online access](https://web.stanford.edu/~hastie/ElemStatLearn/)
- DLR: Chollet, François, and Joseph J. Allaire. Deep Learning with R. Manning, 2018. [online access](https://www.manning.com/books/deep-learning-with-r#toc)
- Sutton, R. S., and Barto, A. G. Reinforcement learning: An introduction. MIT Press, 2020. [online access](http://incompleteideas.net/book/RLbook2020.pdf)

In addition, the following material will also be included (note that you might need to access the material through the Uppsala University network):

- Ruder (2016). An overview of gradient descent optimization algorithms. [online access](https://arxiv.org/abs/1609.04747)
- Efron (2020). Prediction, Estimation, and Attribution. Journal of the American Statistical Association, 115(530), 636-655. [online access](https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1762613) *Note!* You need to be on the Uppsala University network to access the article.
- Kingma DP and Welling M. An Introduction to Variational Autoencoders, 2019. [online access](https://arxiv.org/pdf/1906.02691.pdf)
- Alamar, J. The illustrated Transformer, 2018a. [online](http://jalammar.github.io/illustrated-transformer/)
- Alamar, J. The illustrated BERT, Elmo, and co. (How NLP Cracked Transfer Learning), 2018b. [online](http://jalammar.github.io/illustrated-bert/)
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł. and Polosukhin, I., 2017. Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008). [online](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)
- Griffiths, M. and Steyvers. 2004. Finding Scientific topics [online](https://www.pnas.org/content/pnas/101/suppl_1/5228.full.pdf)
- Blei, D. 2012. Probabilistic Topic Models [online](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf)
- Verma, S. and Rubin, J. (2018) Fairness definitions explained. [online](https://dl.acm.org/doi/pdf/10.1145/3194770.3194776)
- Zhao et al (2023) A Survey on Large Language Models [online](https://arxiv.org/abs/2303.18223)



The literature list might change slightly during the course.

### Video material

- Chen, T. (2016) XGBoost: A scalable Tree Boosting System  [online](https://www.youtube.com/watch?v=Vly8xGnNiWs)
- ISLV: Hastie and Tibshirani, Statistical Learning with R (Video material) [online access](https://www.youtube.com/playlist?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e)
- 3B1B1: Three Blue One Brown on Neural Networks [online access](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- 3B1B2: Three Blue One Brown on Convolutions [online access](https://m.youtube.com/watch?v=KuXjwB4LzSA)
- Dirac, L. (2019) LSTM is dead! Long live Transformers. [online access](https://www.youtube.com/watch?v=S27pHKBEp30) 
- Ng, Andrew (2017) One convolutional layer. [online access](https://www.youtube.com/watch?v=jPOAS7uCODQ&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=7) 
- Hand, Paul, Variational Autoencoders [online](https://www.youtube.com/watch?app=desktop&v=c27SHdQr4lw)
- Phi (2020) Illustrated Guide to Transformers Neural Network: A step by step explanation [online](https://www.youtube.com/watch?v=4Bdc55j80l8)
- UnHeard (2023) Nick Bostrom: How AI will lead to tyranny [online](https://youtu.be/_Oo-m893-xA?si=fFingNh2oNqYX4we)


## Recommended workflow for each block/assignment

1. Read the literature according to the rough course plan
2. Watch the videos to get more indepth knowledge/understanding (however, optional)
3. Do the assignment

## Course practicalities

Online course discussions will be held through Slack. See Studium for details on how to log in.

### Location
The course will have 2 guest lectures that the guest lecturers will give through Zoom. Otherwise, the course will be held on campus. You can find information and support for students on Zoom [here](https://mp.uu.se/c/perm/link?p=267521030). 

## Teachers

Main Teacher: [Måns Magnusson](https://www.mansmagnusson.com/)
Teaching assistant: Andreas Östling

## Course structure

### Main part
The course consists of rougly 8 blocks (weeks) of material. Each week consists of the following (expected workload in parenthesis):
- Two lectures/computer labs (approx. 3h per week)
- Online video material and reading assignments (approx. 4h per week)
- An individual computer assignment (approx. 13 h per week)

### Computer assignments
Each week an individual computer assignment is done with a focus on implementing the main part of the material. Each assignment is completed individually and should follow the computer assignment template.

Students should return the computer assignments no later than **Sunday 23.59 each week**. For a detailed list of deadlines, see the [rough course plan](https://docs.google.com/spreadsheets/d/1HC_QN2mCq9bkCPzmkP8RaR3RokFQCWo9oPuU7rFyR8Y/edit?usp=sharing).

There are two complementary turn-ins of assignments, the last day of the course and roughly 2-4 weeks after the course ends. After the last possible time to turn in the assignment no more chances will be given. In this case, you will be failed on the course and you will need to retake the course next year.

Each assignment will be graded and evaluated within 10 working days.

To pass the assignment 75% of the points are needed. Similarly 75% of the VG assignment is needed to get a VG-point.

### Machine Learning, AI and ethics
A guest lecture will be given on AI and ethics by [Karim Jebari](https://www.iffs.se/en/research/researchers/karim-jebari/) and [Holli Sargeant](https://www.law.cam.ac.uk/people/research-students/h-sargeant/79151).

## Course Project
The last two weeks will focus on a course project where 2-3 students choose their data and create a supervised machine learning predictive model for a real-world dataset. 

You can find details and instructions on the project work [here](https://github.com/MansMeg/IntroML/blob/master/project/).


## Frequently Asked Questions (FAQ)

Frequently asked questions will be collected [here](https://github.com/MansMeg/IntroML/blob/master/FAQ.md).

