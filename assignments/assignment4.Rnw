% !Rnw weave = knitr

\documentclass[11pt,a4paper,english]{article}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{listings}

\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% Normal latex T1-fonts
\usepackage[T1]{fontenc}

% Figures
%\usepackage{graphicx,fancybox,subfigure}

 % AMS-stuff
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsbsy}

 % Misc
\usepackage{verbatim}
\usepackage{url}

\usepackage[round]{natbib}
\bibliographystyle{unsrtnat}

% Page size
\addtolength{\hoffset}{-1cm}
\addtolength{\textwidth}{2cm}
\addtolength{\voffset}{-1cm}
\addtolength{\textheight}{2cm}

% Paragraph
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

% Horizontal line
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% No page numbers
\pagestyle{empty}

% New commands:
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}

\begin{document}

\begin{titlepage}

\center
\textsc{\LARGE Uppsala University}\\[1.5cm] % Name of your university/college
\includegraphics[scale=.2]{files/uu_logo.png}\\[1cm]
\textsc{\Large Machine Learning}\\[0.5cm]
\textsc{\large }\\[0.5cm]

\HRule \\[0.4cm]
{ \huge \bfseries Assignment 4}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

\vfill

\end{titlepage}


\HRule

\input{general_info.tex}

% General Knitr options
% (this cannot be input since the file runs knitr before LaTeX)
<<echo=FALSE,eval=TRUE>>=
options(continue="  ", prompt="> ")
knitr::opts_chunk$set(size = "small")
@

\HRule

\newpage

\tableofcontents

\newpage

%\section{General Questions}

%\input{general_questions_info.tex}

%\begin{enumerate}
%\item describe what dropout does in a CNN.
%\item What is a convolutional kernel/feature map? (max 1 paragraph)
%\item Describe how cross-correlation is related to a convolution with your own words. (max 1 paragraph)
%\item Describe the purpose of a pooling layer in a convolutional architecture. (max 1 paragraph)
% \item Reason about when to gather more data in an ML application? (1-2 paragraphs)
%\item What hyperparameter does \citet{Goodfellow-et-al-2016} find to be the most important to tune, and why? (max 1 paragraph)
%\item What automatic hyperparameter search is recommended by \citet{Goodfellow-et-al-2016}, grid search or random search. Why? (max 1 paragraph)
%\item Describe a good debugging test for an ML algorithm. (max 1 paragraph)
%\item Describe data augmentation in the context of image data and convnets. (max 1 paragraph)
%\item Describe why we primarily focus on fine-tuning layers higher up in neural networks when fine-tuning large pre-trained neural networks. (1-2 paragraphs)
%\end{enumerate}.

%\newpage

\input{general_keras.tex}

\section{Convolutional neural networks using Keras}

We are now going to implement a convolutional neural network using Keras. Here Ch. 5.1-5.3 in \citet{chollet2018deep} and the \href{https://tensorflow.rstudio.com/examples/cifar10_cnn}{following tutorial} might be useful, especially for details on how to load the data. Remember to load the \texttt{tensorflow} R package before loading the \texttt{keras} R package.

If you have installed \texttt{keras}, you can load the MNIST dataset. This dataset contains data on handwritten digits that we want to classify. To access the data, we use \texttt{keras} as follows.

<<echo=TRUE,eval=FALSE>>=
library(keras)
mnist <- dataset_mnist()
mnist$train$x <- mnist$train$x/255
mnist$test$x <- mnist$test$x/255
@

\begin{enumerate}
\item As a first step, we visualize a couple of digits. Include the first three you can find in the training dataset in the report as an image.
<<echo=TRUE,eval=FALSE>>=
idx <- 1
im <- mnist$train$x[idx,,]
# Transpose the image
im <- t(apply(im, 2, rev))
image(1:28, 1:28, im, col=gray((0:255)/255), xlab = "", ylab = "",
        xaxt='n', yaxt='n', main=paste(mnist$train$y[idx]))
@

\item Implement a Convolutional Neural Network for the MNIST dataset. The network should have two convolutional layers as follows.
<<>>=
## _______________________________________________________________________
## Layer (type)                     Output Shape                Param #
## =======================================================================
## conv2d (Conv2D)                  (None, 26, 26, 32)          320
## _______________________________________________________________________
## max_pooling2d (MaxPooling2D)     (None, 13, 13, 32)          0
## _______________________________________________________________________
## conv2d (Conv2D)                  (None, 11, 11, 32)          9248
## _______________________________________________________________________
## flatten (Flatten)                (None, 3872)                0
## _______________________________________________________________________
## dense (Dense)                    (None, 64)                  247872
## _______________________________________________________________________
## dense (Dense)                    (None, 10)                  650
## =======================================================================
## Total params: 258,090
## Trainable params: 258,090
## Non-trainable params: 0
@
\item Explain why there are 320 parameters in the first layer. How many are kernel weights (and why), and how many biases?
\item Train the network using Keras. What is your loss and accuracy on the MNIST dataset?
\item Choose at least three hyper-parameters you would like to evaluate (\citet[see Table 11.1 in ][]{Goodfellow-et-al-2016}). Use random search \citet[see Ch. 11.4.4 in ][]{Goodfellow-et-al-2016} and train 10 different models with random hyper-parameter settings and store the validation accuracy of your network. Based on these result, choose the best hyper-parameter setting for your network. Print the code and the accuracy of your final model. You can choose the marginal distribution for the hyper-parameters yourself.
\item As the next step, we will implement a convolutional neural network for the CIFAR-10 dataset using \texttt{dataset\_cifar10()}. See the \href{https://tensorflow.rstudio.com/examples/cifar10_cnn}{tutorial} for details on how to load data. Implement a similar CNN as in the tutorial. That is:
<<>>=
## Model: "sequential"
## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #
## ===========================================================================
## conv2d (Conv2D)                  (None, 30, 30, 32)            896
## ___________________________________________________________________________
## max_pooling2d (MaxPooling2D)     (None, 15, 15, 32)            0
## ___________________________________________________________________________
## conv2d_1 (Conv2D)                (None, 13, 13, 64)            18496
## ___________________________________________________________________________
## max_pooling2d_1 (MaxPooling2D)   (None, 6, 6, 64)              0
## ___________________________________________________________________________
## conv2d_2 (Conv2D)                (None, 4, 4, 64)              36928
## ___________________________________________________________________________
## flatten (Flatten)                (None, 1024)                  0
## ___________________________________________________________________________
## dense (Dense)                    (None, 64)                    65600
## ___________________________________________________________________________
## dense_1 (Dense)                  (None, 10)                    650
## ===========================================================================
## Total params: 122,570
## Trainable params: 122,570
## Non-trainable params: 0
## ___________________________________________________________________________

@
\emph{Note!} This problem is more complex than the MNIST problem, so don't be surprised if you get lower accuracy than you got on the MNIST dataset.
\item Visualize one image of your choice from the CIFAR dataset together with its class/category.
\item Why do we now have 896 parameters in the first convolutional layer?
\item Try out and compare at least three different networks for the CIFAR data. Describe the networks (include the keras model output), why you choose them, and the Keras model output. \citet[Ch. 11-11.5]{Goodfellow-et-al-2016} and \citep[Ch. 5.3]{chollet2018deep} might give some suggestions. \label{item:three}
\end{enumerate}

\newpage

\section{* Implementing a convolutional layer}

To get VG on this assignment, you can choose to make this task OR the task on transfer learning below. You are also free to do both, if you want. As long as you pass one of the two VG assignments you will get a VG point. Although, please only write down the time it took to do the VG assignment for one of the tasks.

\input{distinction_task.tex}


As a first step, we will implement a layer of a convolutional neural network with one filter. We will here not train the layer, only implement it to understand the inner workings. You are not allowed to use \texttt{convolve()} in R in the final solution, but you can use it to debug your code if you want to.

Some good material for this exercise is Figure 9.1 in \citet{Goodfellow-et-al-2016} and the video \citet{ng2017}.

Start by importing examples from the MNIST dataset as follows.

<<eval = TRUE>>=
library(uuml)
data("mnist_example")
@

To visualize an image use:

<<eval = FALSE>>=
im <- mnist_example[["5"]]
image(1:ncol(im), 1:nrow(im), im,
      xlab = "", ylab = "",
      xaxt='n', yaxt='n', main="4")
@

<<echo = FALSE>>=
convolution <- function(X,K){
  matrix(c(-1, 27,
           -36, -36), byrow = TRUE, ncol = 2)
}

convolutional_layer <- function(X,K,b,activation){
      matrix(c(99,  127,
               64, 64), byrow = TRUE, ncol = 2)
}

maxpool_layer <- function(X){
  matrix(c(250,  144,
           198, 241), byrow = TRUE, ncol = 2)
}
@


\begin{enumerate}
\item Visualize the MNIST example digit 4.
\item Implement a convolution function called \texttt{convolution(X, K)} that takes an input MNIST image (\texttt{X}), an arbitrary large square kernel (\texttt{K}) and returns a valid feature map. Below is an example of how it should work.
<<>>=
X <- mnist_example[["4"]][12:15,12:15]
X

K <- matrix(c(-0.5, -0.5, -0.5,
              1,  1,  1,
              -0.5, -0.5, -0.5), nrow = 3, byrow = TRUE)
K

convolution(X, K)
@
\item Visualize the feature map of MNIST example digit 4 using the above two by two kernel \texttt{K}.
\item Now implement all steps in a \texttt{convolutional\_layer(X, K, b, activation)} function that takes the kernel, bias and activation function. It should work as follows.
<<>>=
relu <- function(x) max(0, x)
convolutional_layer(X, K, 100, relu)
@
\item Run your convolutional layer on MNIST example digit 4 with bias -150. Visualize the feature map as you visualize the original image. What does the filter seem to capture?
\item Now transpose your filter and run your convolutional layer on MNIST example digit 4 with bias -150. Visualize the feature map. What does that transposed filter seem to capture?
\item As the last step in our convolutional layer, implement a two by two, two stride max-pooling layer. It should work as follows.
<<>>=
X <- mnist_example[["4"]][12:15,12:15]
maxpool_layer(X)
@
\item Now put it all together and visualize the final output of your own convolutional layer. Visualize the feature map.
<<eval=FALSE>>=
X <- mnist_example[["4"]]
relu <- function(x) max(0, x)
output <- maxpool_layer(convolutional_layer(X, K, -370, relu))
@

\end{enumerate}

\newpage

\section{* Transfer learning using VGG16}

To get VG on this assignment, you can choose to make this task OR the task on implementing a convolutional layer above. You are also free to do both, if you want. As long as you pass one of the two VG assignments you will get a VG point. Although, please only write down the time it took to do the VG assignment for one of the tasks.

\input{distinction_task.tex}

\emph{Note!} This task can be a computationally heavy.

As the last step, we will look into using transfer learning as a quick way of improving the prediction accuracy on the cifar-10 dataset. Here Ch. 5.3 in \citet{chollet2018deep} or \href{https://blogs.rstudio.com/ai/posts/2017-12-14-image-classification-on-small-datasets/}{this tutorial} might be helpful.

You can find the current state-of-the-art neural networks for the cifar-10 dataset \href{https://benchmarks.ai/cifar-10}{here}. Feel free to read some of the papers and be inspired on how to improve your neural network.

\begin{enumerate}
\item Using Keras, download the VGG16 convolutional neural network convolutional base. Just download the convolutional base. We are going to use the network on the cifar-10 dataset so change the \texttt{input\_size} to \texttt{c(32, 32, 3)}.
\item Now add a dense layer with 64 hidden nodes (as in the previous exercise). Include the Keras model output in the assignment report. How many parameters do you have in the dense top layer (compared to the CNN in the previous part)?
\item Now, freeze the convolutional base and train the dense top layer of your network on the cifar-10 dataset. Run it for five epochs. \emph{Note!} This will take time. Don't be surprised if you need roughly 200s per epoch or more. Also, remember to freeze the convolutional base!
\item Report your final accuracy. How does this compare to the previous model for the cifar data?
\end{enumerate}

\newpage
\bibliography{bibliography}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
