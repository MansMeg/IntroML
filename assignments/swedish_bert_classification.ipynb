{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hLHn47uGjjX2",
        "hUvDR5_mgNZ7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MansMeg/IntroML/blob/master/assignments/swedish_bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of motions from the Swedish Parliament (Riksdagen) using a Swedish BERT model\n",
        "\n",
        "Here we demonstrate how to perform document classification using models from the `transformers` Python library. We will be using a dataset consisting of parliamentary motions from the Swedish Parliament (Riksdagen). Can we predict which party authored a parliamentary motion using only the text of a motion as input? \n",
        "\n",
        "Huggingface `transformers` library has many high level abstractions for making training of large language models \"simpler\". In particular there is the `Trainer` class for launching training, and the `datasets` library for loading and working with Huggingface datasets. There are already [plenty](https://huggingface.co/course/chapter3/3?fw=pt) of guides on the internet showing [how to use these tools](https://huggingface.co/transformers/v3.2.0/custom_datasets.html#fine-tuning-with-trainer). \n",
        "\n",
        "While these high level abstractions might help make tutorials more succinct and straight to the point, it usually comes at the cost of creating barriers for students and practicians who at some later point may need to adapt their use to custom datasets and (non-standard) training objectives.\n",
        "\n",
        "The patterns used in this guide will therefore all be standard Pytorch abstractions for creating datasets, dataloaders and writing your own custom training loops for transformer model trained for Swedish. These patterns are general for Pytorch, and thus applicable in almost all situations where you're working with Pytorch models. Your capacity to customize and change things is only limited by your knowledge of Pytorch and your basic coding abilities. "
      ],
      "metadata": {
        "id": "3rUi3l-lEOpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up data\n",
        "\n",
        "### Installing the `transformers` library\n",
        "\n",
        "Google Colab doesn't have `transformers` preinstalled. Let's install it first.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ueKXhHifhKRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRpTgvv0hX5r",
        "outputId": "c7309aab-0513-466f-e120-7befd56a1f1a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the Swedish parliamentary corpus\n",
        "\n",
        "We download a dataset of parliamentary motions from the years 2014-2021 that has been collected from the Swedish parliament open data and prepared in advance. The interested reader can see where the data was [downloaded from](https://github.com/kb-labb/bertopic_workshop/blob/main/download_data.sh) and how it was [preprocessed](https://github.com/kb-labb/bertopic_workshop/blob/main/parse_motioner.py). "
      ],
      "metadata": {
        "id": "z2C6ES5LFq-M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_28mJ1GWCB4Y",
        "outputId": "2e6282a0-2e40-4b81-b689-e038069f97df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100     8    0     8    0     0      5      0 --:--:--  0:00:01 --:--:--     5\n",
            "100 90.6M  100 90.6M    0     0  10.7M      0  0:00:08  0:00:08 --:--:-- 18.4M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://kungliga-biblioteket.box.com/shared/static/ii4yhmj0f5do0ifjtj1nzb13iy7dkq5e --output motioner_2014_2021.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read our data file `motioner_2014_2021.parquet` as a dataframe and display a table of it below.\n",
        "\n",
        "Here's a brief explanation of some column variables whose names may not be fully self-explanatory:\n",
        "\n",
        "* **doc_id**: Unique id that identifies each parliamentary motion document.\n",
        "* **text**: Contains the full body text of the parliamentary motion (truncated in the table below). \n",
        "* **datum**: Date.\n",
        "* **dokument_html_url**: An URL to the document in html-format on Riksdagen's website.\n",
        "* **titel**: Title.\n",
        "* **subtitel**: Who wrote the motion (\"m.fl.\" can be translated \"et al.\"). \n",
        "* **organ**: Abbreviations of the different [committees (\"utskott\")](https://sv.wikipedia.org/wiki/Riksdagsutskott_(Sverige)) of the riksdag.  \n",
        "* **subtyp**: Type of motion. Whether it was submitted by an individual member (Enskild motion), a committee (Kommittémotion), a political party (partimotion), or several parties (flerpartimotion). \n",
        "* **authors_\\***: How many authors from each individual party that wrote the motion. \n",
        "* **nr_authors**: Total number of listed authors.\n",
        "* **party**: Party abbreviations of party/parties involved in writing the motion, separated by commas.\n",
        "* **single_party_authors**: Boolean variable indicating whether the authors of the motion were all from the same party (True), or whether it was a collaboration between several parties (False).\n",
        "\n",
        "We use the `pandas` library to read in the corpus and display the five first motions. "
      ],
      "metadata": {
        "id": "ePb4_9EvHkUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet(\"motioner_2014_2021.parquet\")\n",
        "print(f\"The dataset consists of a total of {len(df)} motions.\")\n",
        "df # Display only the 5 first rows of the dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "Quc3yyagHNCc",
        "outputId": "5ae2d09d-c6e8-4da0-b88f-668dd85bcc09"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset consists of a total of 29851 motions.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         dok_id                                               text      datum  \\\n",
              "0      H9023691  Den svenska gruv- och mineralnäringen var med ... 2021-10-05   \n",
              "1      H6022337  Regeringen beslutade under 2017 att anta en na... 2018-11-29   \n",
              "2      H8023930  Regeringen föreslår genom proposition 2020/21:... 2021-04-07   \n",
              "3        H80268  Under en sommarkväll 2018 misshandlades en per... 2020-09-11   \n",
              "4      H3021446  Företag skapar arbetstillfällen och bidrar til... 2015-10-05   \n",
              "...         ...                                                ...        ...   \n",
              "29846  H9021195  Färjetrafiken till Gotland är öns landsväg, de... 2021-09-30   \n",
              "29847  H5023547  Länge har problemet just varit att Sverige int... 2017-10-05   \n",
              "29848  H2021061  Inför riksdagsvalen går debattens vågor höga. ... 2014-11-07   \n",
              "29849  H5023948  Riksrevisionen riktar mycket allvarlig kritik ... 2018-01-09   \n",
              "29850  H3021050  Delningsekonomin, som innebär att vi delar all... 2015-10-05   \n",
              "\n",
              "                                dokument_url_html  \\\n",
              "0      http://data.riksdagen.se/dokument/H9023691   \n",
              "1      http://data.riksdagen.se/dokument/H6022337   \n",
              "2      http://data.riksdagen.se/dokument/H8023930   \n",
              "3        http://data.riksdagen.se/dokument/H80268   \n",
              "4      http://data.riksdagen.se/dokument/H3021446   \n",
              "...                                           ...   \n",
              "29846  http://data.riksdagen.se/dokument/H9021195   \n",
              "29847  http://data.riksdagen.se/dokument/H5023547   \n",
              "29848  http://data.riksdagen.se/dokument/H2021061   \n",
              "29849  http://data.riksdagen.se/dokument/H5023948   \n",
              "29850  http://data.riksdagen.se/dokument/H3021050   \n",
              "\n",
              "                                                   titel  \\\n",
              "0          En konkurrenskraftig gruvnäring för framtiden   \n",
              "1                        Starkare nationell cykelpolitik   \n",
              "2      med anledning av prop. 2020/21:159 Vissa ident...   \n",
              "3                                  Utvidgad nödvärnsrätt   \n",
              "4                Företagsdag på högstadiet och gymnasiet   \n",
              "...                                                  ...   \n",
              "29846  Statligt ansvar för en reservhamn i Gotlandstr...   \n",
              "29847  Visum och bidragssanktioner mot länder som int...   \n",
              "29848                  Förbättrad kvalitet i valdebatten   \n",
              "29849  med anledning av skr. 2017/18:68 Riksrevisione...   \n",
              "29850                                    Delningsekonomi   \n",
              "\n",
              "                                                subtitel organ  \\\n",
              "0                            av Lars Hjälmered m.fl. (M)    NU   \n",
              "1                                 av Emma Berginger (MP)    TU   \n",
              "2                      av Christina Höj Larsen m.fl. (V)   SfU   \n",
              "3      av Markus Wiechel och Alexander Christiansson ...   JuU   \n",
              "4                                 av Johan Nissinen (SD)   UbU   \n",
              "...                                                  ...   ...   \n",
              "29846                               av Lars Thomsson (C)    TU   \n",
              "29847                               av Kent Ekeroth (SD)   SfU   \n",
              "29848                              av Betty Malmberg (M)    KU   \n",
              "29849  av Stefan Jakobsson och Robert Stenkvist (båda...   UbU   \n",
              "29850                         av Jessica Rosencrantz (M)    NU   \n",
              "\n",
              "               subtyp  hangar_id  authors_V  ...  authors_MP  authors_C  \\\n",
              "0      Kommittémotion    5109435          0  ...           0          0   \n",
              "1      Enskild motion    5012022          0  ...           1          0   \n",
              "2      Kommittémotion    5092870          5  ...           0          0   \n",
              "3      Enskild motion    5066863          0  ...           0          0   \n",
              "4      Enskild motion    4386670          0  ...           0          0   \n",
              "...               ...        ...        ...  ...         ...        ...   \n",
              "29846  Enskild motion    5106758          0  ...           0          1   \n",
              "29847  Enskild motion    4773394          0  ...           0          0   \n",
              "29848  Enskild motion    3111220          0  ...           0          0   \n",
              "29849  Enskild motion    4785744          0  ...           0          0   \n",
              "29850  Enskild motion    4386185          0  ...           0          0   \n",
              "\n",
              "       authors_L  authors_KD  authors_M  authors_SD  authors_independent  \\\n",
              "0              0           0          4           0                    0   \n",
              "1              0           0          0           0                    0   \n",
              "2              0           0          0           0                    0   \n",
              "3              0           0          0           2                    0   \n",
              "4              0           0          0           1                    0   \n",
              "...          ...         ...        ...         ...                  ...   \n",
              "29846          0           0          0           0                    0   \n",
              "29847          0           0          0           1                    0   \n",
              "29848          0           0          1           0                    0   \n",
              "29849          0           0          0           2                    0   \n",
              "29850          0           0          1           0                    0   \n",
              "\n",
              "       nr_authors  party single_party_authors  \n",
              "0               4      M                 True  \n",
              "1               1     MP                 True  \n",
              "2               5      V                 True  \n",
              "3               2     SD                 True  \n",
              "4               1     SD                 True  \n",
              "...           ...    ...                  ...  \n",
              "29846           1      C                 True  \n",
              "29847           1     SD                 True  \n",
              "29848           1      M                 True  \n",
              "29849           2     SD                 True  \n",
              "29850           1      M                 True  \n",
              "\n",
              "[29851 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f066265-a1ab-45ac-8622-88417181e607\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dok_id</th>\n",
              "      <th>text</th>\n",
              "      <th>datum</th>\n",
              "      <th>dokument_url_html</th>\n",
              "      <th>titel</th>\n",
              "      <th>subtitel</th>\n",
              "      <th>organ</th>\n",
              "      <th>subtyp</th>\n",
              "      <th>hangar_id</th>\n",
              "      <th>authors_V</th>\n",
              "      <th>...</th>\n",
              "      <th>authors_MP</th>\n",
              "      <th>authors_C</th>\n",
              "      <th>authors_L</th>\n",
              "      <th>authors_KD</th>\n",
              "      <th>authors_M</th>\n",
              "      <th>authors_SD</th>\n",
              "      <th>authors_independent</th>\n",
              "      <th>nr_authors</th>\n",
              "      <th>party</th>\n",
              "      <th>single_party_authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>H9023691</td>\n",
              "      <td>Den svenska gruv- och mineralnäringen var med ...</td>\n",
              "      <td>2021-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H9023691</td>\n",
              "      <td>En konkurrenskraftig gruvnäring för framtiden</td>\n",
              "      <td>av Lars Hjälmered m.fl. (M)</td>\n",
              "      <td>NU</td>\n",
              "      <td>Kommittémotion</td>\n",
              "      <td>5109435</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H6022337</td>\n",
              "      <td>Regeringen beslutade under 2017 att anta en na...</td>\n",
              "      <td>2018-11-29</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H6022337</td>\n",
              "      <td>Starkare nationell cykelpolitik</td>\n",
              "      <td>av Emma Berginger (MP)</td>\n",
              "      <td>TU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5012022</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>MP</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>H8023930</td>\n",
              "      <td>Regeringen föreslår genom proposition 2020/21:...</td>\n",
              "      <td>2021-04-07</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H8023930</td>\n",
              "      <td>med anledning av prop. 2020/21:159 Vissa ident...</td>\n",
              "      <td>av Christina Höj Larsen m.fl. (V)</td>\n",
              "      <td>SfU</td>\n",
              "      <td>Kommittémotion</td>\n",
              "      <td>5092870</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>V</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>H80268</td>\n",
              "      <td>Under en sommarkväll 2018 misshandlades en per...</td>\n",
              "      <td>2020-09-11</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H80268</td>\n",
              "      <td>Utvidgad nödvärnsrätt</td>\n",
              "      <td>av Markus Wiechel och Alexander Christiansson ...</td>\n",
              "      <td>JuU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5066863</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H3021446</td>\n",
              "      <td>Företag skapar arbetstillfällen och bidrar til...</td>\n",
              "      <td>2015-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H3021446</td>\n",
              "      <td>Företagsdag på högstadiet och gymnasiet</td>\n",
              "      <td>av Johan Nissinen (SD)</td>\n",
              "      <td>UbU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4386670</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29846</th>\n",
              "      <td>H9021195</td>\n",
              "      <td>Färjetrafiken till Gotland är öns landsväg, de...</td>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H9021195</td>\n",
              "      <td>Statligt ansvar för en reservhamn i Gotlandstr...</td>\n",
              "      <td>av Lars Thomsson (C)</td>\n",
              "      <td>TU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>5106758</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29847</th>\n",
              "      <td>H5023547</td>\n",
              "      <td>Länge har problemet just varit att Sverige int...</td>\n",
              "      <td>2017-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H5023547</td>\n",
              "      <td>Visum och bidragssanktioner mot länder som int...</td>\n",
              "      <td>av Kent Ekeroth (SD)</td>\n",
              "      <td>SfU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4773394</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29848</th>\n",
              "      <td>H2021061</td>\n",
              "      <td>Inför riksdagsvalen går debattens vågor höga. ...</td>\n",
              "      <td>2014-11-07</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H2021061</td>\n",
              "      <td>Förbättrad kvalitet i valdebatten</td>\n",
              "      <td>av Betty Malmberg (M)</td>\n",
              "      <td>KU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>3111220</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29849</th>\n",
              "      <td>H5023948</td>\n",
              "      <td>Riksrevisionen riktar mycket allvarlig kritik ...</td>\n",
              "      <td>2018-01-09</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H5023948</td>\n",
              "      <td>med anledning av skr. 2017/18:68 Riksrevisione...</td>\n",
              "      <td>av Stefan Jakobsson och Robert Stenkvist (båda...</td>\n",
              "      <td>UbU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4785744</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>SD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29850</th>\n",
              "      <td>H3021050</td>\n",
              "      <td>Delningsekonomin, som innebär att vi delar all...</td>\n",
              "      <td>2015-10-05</td>\n",
              "      <td>http://data.riksdagen.se/dokument/H3021050</td>\n",
              "      <td>Delningsekonomi</td>\n",
              "      <td>av Jessica Rosencrantz (M)</td>\n",
              "      <td>NU</td>\n",
              "      <td>Enskild motion</td>\n",
              "      <td>4386185</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29851 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f066265-a1ab-45ac-8622-88417181e607')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f066265-a1ab-45ac-8622-88417181e607 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f066265-a1ab-45ac-8622-88417181e607');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the corpus\n",
        "\n",
        "Before we can get started, we first need to \n",
        "\n",
        "1. create an integer label column we want to classify.\n",
        "2. divide our data into a training and evaluation set.\n",
        "\n",
        "A small proportion of parliamentary motions are also the result of several members of parliament collaborating across party lines. In this guide, we make it simple for ourselves and simply filter out the observations with multiple authors from different political parties. \n",
        "\n",
        "For now, we include only 'enskilda motioner' below.\n",
        "\n",
        "Training can take upwards to 2-3 hours if we include all observations. For this reason we select a subset of the data spanning the last mandate period from 2018-10-01 and forwards."
      ],
      "metadata": {
        "id": "ZUpynRhUIwyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"datum\"] >= \"2018-10-01\"].reset_index(drop=True)\n",
        "df = df[df[\"single_party_authors\"] == True].reset_index(drop=True)\n",
        "df = df[df[\"subtyp\"] == \"Enskild motion\"] # Filter to keep only enskilda motioner\n",
        "label_mapping = {\n",
        "    0: \"V\",\n",
        "    1: \"S\",\n",
        "    2: \"MP\",\n",
        "    3: \"C\",\n",
        "    4: \"L\",\n",
        "    5: \"M\",\n",
        "    6: \"KD\",\n",
        "    7: \"SD\",\n",
        "    8: \"independent\",\n",
        "}\n",
        "label_mapping = {v: k for k, v in label_mapping.items()} # Reverse key/value\n",
        "df[\"label\"] = df[\"party\"].map(label_mapping)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df_train = df.sample(frac=0.85, random_state=5)\n",
        "df_valid = df.drop(df_train.index)\n",
        "\n",
        "df_train[[\"dok_id\", \"text\", \"party\", \"label\", \"titel\", \"subtitel\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "RLaUGkjsH5FC",
        "outputId": "292fdb8e-4f96-4dfb-89cf-7e4652275704"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         dok_id                                               text  \\\n",
              "5177   H9021161  För många av våra äldre tonåringar, inte minst...   \n",
              "928    H8022931  Sverige har en mycket lång kust med öppna strä...   \n",
              "833    H8021154  Det är angeläget att hela Sverige ska leva. Vi...   \n",
              "2681    H802752  Den fria och självständiga idrottsrörelsen är ...   \n",
              "7683   H6021956  Sverigedemokraternas utgångspunkt är att tille...   \n",
              "...         ...                                                ...   \n",
              "4346     H90279  Kvinnor i Saudiarabien, Afghanistan och Iran d...   \n",
              "3280   H9021259  Utbyggnaden av barnomsorg i offentlig regi har...   \n",
              "7359   H8022312  Bostadsrätten är idag en boendeform som i grun...   \n",
              "10338  H9021882  Länder som Tyskland och Danmark har länge anvä...   \n",
              "5938   H7022175  Alliansregeringen gjorde en satsning år 2010 f...   \n",
              "\n",
              "             party  label                                          titel  \\\n",
              "5177            KD      6                                    A-traktorer   \n",
              "928              C      3                                   Marint skräp   \n",
              "833              M      5         Ökad robusthet med fleråriga tågplaner   \n",
              "2681             S      1                  Momsregler och civilsamhället   \n",
              "7683            SD      7           Sverigedemokraternas biståndspolitik   \n",
              "...            ...    ...                                            ...   \n",
              "4346   independent      8     Sanktioner mot bl.a. Iran och Saudiarabien   \n",
              "3280             S      1  Barnomsorg på de tider då föräldrarna arbetar   \n",
              "7359             M      5         Stärkt egendomsskydd för bostadsrätter   \n",
              "10338            M      5                               Kulgevärsmetoden   \n",
              "5938             M      5                                Trygghetsboende   \n",
              "\n",
              "                                                subtitel  \n",
              "5177                         av Kjell-Arne Ottosson (KD)  \n",
              "928    av Fredrik Christensson och Rickard Nordin (bå...  \n",
              "833                          av Ann-Sofie Lifvenhage (M)  \n",
              "2681                             av Anna Wallentheim (S)  \n",
              "7683                        av Ludvig Aspling m.fl. (SD)  \n",
              "...                                                  ...  \n",
              "4346                             av Amineh Kakabaveh (-)  \n",
              "3280                              av Hillevi Larsson (S)  \n",
              "7359                                av Kjell Jansson (M)  \n",
              "10338                              av Sten Bergheden (M)  \n",
              "5938         av Lotta Finstorp och Edward Riedl (båda M)  \n",
              "\n",
              "[10060 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69b69612-ea07-442c-8407-20dec43964b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dok_id</th>\n",
              "      <th>text</th>\n",
              "      <th>party</th>\n",
              "      <th>label</th>\n",
              "      <th>titel</th>\n",
              "      <th>subtitel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5177</th>\n",
              "      <td>H9021161</td>\n",
              "      <td>För många av våra äldre tonåringar, inte minst...</td>\n",
              "      <td>KD</td>\n",
              "      <td>6</td>\n",
              "      <td>A-traktorer</td>\n",
              "      <td>av Kjell-Arne Ottosson (KD)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>H8022931</td>\n",
              "      <td>Sverige har en mycket lång kust med öppna strä...</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>Marint skräp</td>\n",
              "      <td>av Fredrik Christensson och Rickard Nordin (bå...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>833</th>\n",
              "      <td>H8021154</td>\n",
              "      <td>Det är angeläget att hela Sverige ska leva. Vi...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Ökad robusthet med fleråriga tågplaner</td>\n",
              "      <td>av Ann-Sofie Lifvenhage (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681</th>\n",
              "      <td>H802752</td>\n",
              "      <td>Den fria och självständiga idrottsrörelsen är ...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Momsregler och civilsamhället</td>\n",
              "      <td>av Anna Wallentheim (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7683</th>\n",
              "      <td>H6021956</td>\n",
              "      <td>Sverigedemokraternas utgångspunkt är att tille...</td>\n",
              "      <td>SD</td>\n",
              "      <td>7</td>\n",
              "      <td>Sverigedemokraternas biståndspolitik</td>\n",
              "      <td>av Ludvig Aspling m.fl. (SD)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4346</th>\n",
              "      <td>H90279</td>\n",
              "      <td>Kvinnor i Saudiarabien, Afghanistan och Iran d...</td>\n",
              "      <td>independent</td>\n",
              "      <td>8</td>\n",
              "      <td>Sanktioner mot bl.a. Iran och Saudiarabien</td>\n",
              "      <td>av Amineh Kakabaveh (-)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3280</th>\n",
              "      <td>H9021259</td>\n",
              "      <td>Utbyggnaden av barnomsorg i offentlig regi har...</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>Barnomsorg på de tider då föräldrarna arbetar</td>\n",
              "      <td>av Hillevi Larsson (S)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7359</th>\n",
              "      <td>H8022312</td>\n",
              "      <td>Bostadsrätten är idag en boendeform som i grun...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Stärkt egendomsskydd för bostadsrätter</td>\n",
              "      <td>av Kjell Jansson (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10338</th>\n",
              "      <td>H9021882</td>\n",
              "      <td>Länder som Tyskland och Danmark har länge anvä...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Kulgevärsmetoden</td>\n",
              "      <td>av Sten Bergheden (M)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5938</th>\n",
              "      <td>H7022175</td>\n",
              "      <td>Alliansregeringen gjorde en satsning år 2010 f...</td>\n",
              "      <td>M</td>\n",
              "      <td>5</td>\n",
              "      <td>Trygghetsboende</td>\n",
              "      <td>av Lotta Finstorp och Edward Riedl (båda M)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10060 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69b69612-ea07-442c-8407-20dec43964b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69b69612-ea07-442c-8407-20dec43964b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69b69612-ea07-442c-8407-20dec43964b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Pytorch Dataset\n",
        "\n",
        "Pytorch recommends separating your dataset code from your modeling code. They provide two \"data primitives\" to help the user do this: the [`Dataset` class and the `DataLoader`](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders). \n",
        "\n",
        "* The `Dataset` is a way of defining how to fetch and sample our dataset's variables and labels one by one. \n",
        "* The `DataLoader` is an abstraction that parallelizes the loading of samples from your `Dataset`, ensuring samples are continuously fetched in advance in separate processes, and passed to your model (e.g. if running on a GPU) without it having to pause and wait for the CPU to finish loading a new batch/sample each iteration. \n",
        "\n",
        "We start with writing a `Dataset` class for our setting. Every dataset class should *always* have the methods `__init__`, `__len__` and `__getitem__`. Their purpose is briefly explained in the comments of the example custom Dataset class implementation below, but you may also read about them in Pytorch's [guide on Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#init).\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, my_texts, my_labels):\n",
        "        # Instance attributes that are shared and can be used in other methods\n",
        "        # of the class by writing self.attribute_name .\n",
        "        # Only run once, when the Dataset is instantiated.\n",
        "        self.my_texts = my_texts\n",
        "        self.my_labels = my_labels\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "\n",
        "    def __len__(self):\n",
        "        # A way of telling the class how many observations there are in\n",
        "        # your dataset. So that it knows the range of indices it can sample.\n",
        "        return len(self.my_texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Where we load and return a sample. __getitem__ is called whenever\n",
        "        # we use indexing on our dataset, e.g. mydataset[13], mydataset[0], etc\n",
        "        # \"index\" changes each iteration.\n",
        "        text_selected_obs = self.my_texts[index]\n",
        "        label_selected_obs = self.my_labels[index]\n",
        "\n",
        "        # Tokenize the text (can be done outside Dataset too).\n",
        "        # Pads to the model's maximum allowed sequence length if shorter.\n",
        "        tokenized_text = self.tokenizer(\n",
        "            text_selected_obs, padding=\"max_length\", truncation=True, return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # tokenized_text is a dictionary, so we squeeze in the label\n",
        "        # as an entry there as well, and just return everything as a\n",
        "        # single object.\n",
        "        tokenized_text[\"label\"] = torch.tensor(label_selected_obs)\n",
        "\n",
        "        return tokenized_text\n",
        "\n",
        "```\n",
        "\n",
        "Let's create our own Dataset class for the parliamentary motions below. We'll name it `MotionerDataset`, and make it simple for ourselves by passing our entire dataframe as input:"
      ],
      "metadata": {
        "id": "CRPYNOkKVYAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "class MotionerDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        df_row = self.df.iloc[index]\n",
        "\n",
        "        label = df_row[\"label\"]\n",
        "        text = df_row[\"text\"]\n",
        "\n",
        "        # padding=\"max_length\" pads to the models maximum allowed length. \n",
        "        # Only do this if you expect most texts to be as long or longer than\n",
        "        # the maximum sequence length of the model (512 tokens in this case).\n",
        "        # We truncate if the sequence is too long.\n",
        "        tokenized_text = self.tokenizer(\n",
        "            text, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        label = torch.tensor(label)\n",
        "        tokenized_text[\"label\"] = label\n",
        "\n",
        "        return tokenized_text"
      ],
      "metadata": {
        "id": "qmqTeuaAMDxS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's instantiate our dataset and see what it returns."
      ],
      "metadata": {
        "id": "zIPajP6bk1rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MotionerDataset(df=df_train)\n",
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnY3z3WlVSaG",
        "outputId": "1b1406f6-eea9-47aa-a3d7-786f3f97de93"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2,   359,   621,    65,  1244,  2332, 20408,    19,   127,  1706,\n",
              "            68, 13034,    19,    54,  6342, 49792,    52,   264,   101,    52,\n",
              "         45959,    59,   408,  3497,   292,    65, 46531,     7, 19946,    54,\n",
              "            59,   818,    31,   195,   216,    43,   621,    54,    82,   524,\n",
              "           137, 47201,    67,  1126,    67,  1804,   845,     7,  2278,   137,\n",
              "          3544, 35591, 47201,   390,    59, 24681,   256,   356,  2392,   802,\n",
              "         26114,  5722, 49799,     7,   285,  6342, 49792,    52,   264,   101,\n",
              "            52, 22823,   393,  3802, 25913,    31,  5658,   419,   633,   284,\n",
              "            21,    19,    36,  6036,   108,    97,  3930,  5658, 26031,   390,\n",
              "            59,  2393,    52, 24681,    67,   393,   690,    31,   885,   633,\n",
              "           284,    21,     7, 36630, 26044, 10303,  3513,   393,  3802, 25913,\n",
              "            31,  3506,   856,   633,   284,    21,     7,  1298,    51,  2222,\n",
              "         40913,     9,   230,   198,    67, 26114,  5722, 49799, 24681,   202,\n",
              "           393,  4244, 20256,   390,   230,   356,  2392,   741,    31,    59,\n",
              "         37098, 37404,    31,    59,  6342, 49792,    52,   264,   101,    52,\n",
              "         22823,     7,  2861,   403,  1974, 16645,   367,    36,  3818,  6955,\n",
              "           102, 12885,    67,   945,    43,  1021,  8233,   587, 11879,   100,\n",
              "          7780,  8438,  4112,   130,  3710,   178, 22050,    66,  4530, 11955,\n",
              "          1159,  1998, 49796,     7,   864,  1357,    31,   825,  3514,  3292,\n",
              "            59, 25251, 33875,    43,   621,  4687,    68, 13034,    19,   127,\n",
              "          1706,   256, 26242,  5867,     7,     3,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'label': tensor(6)}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do the different dictionary keys mean? And why are there lots of zeroes at the end of our `input_ids`?\n",
        "\n",
        "* `input_ids`: Your tokenized text mapped to integers. The model expects the input as integers, so that it can select the correct row from the vocabulary token embedding matrix. These vectors are what is the actual input to the model. And every single row of the vocabulary embedding matrix maps to a certain token (via the input_id integer of the token). \n",
        "* `token_type_ids`: This is a way of keeping track of the indices of each sequence if we pass multiple texts as a single observation. This exists for BERT mainly because BERT has the pretraining task of `next_sentence_prediction` (two texts are passed as a single sequence), and because sometimes multiple shorter sequences are stacked and passed as one to fill up the maximum sequence length of the model. This is done in order not to waste compute by needlessly padding with 0s. In our case, we only put one text in the input sequence and thus don't need the `token_type_ids` to be able to separate them. We can in fact specify `return_token_type_ids=False` in the tokenizer to let it know that it shouldn't return them.\n",
        "* `attention_mask`: What tokens should the model ignore when computing attentions and losses? We want to ignore `[PAD]` tokens that sometimes need to be added at the end of a sequence to ensure all inputs in a given batch are of the same length/dimensions when passed to the model. \n",
        "* `label`: This is something we ourselves inserted into the dictionary in our `MotionerDataset` before returning it. We will need it later when computing the loss. \n",
        "\n",
        "We can check which tokens the integer `input_ids` map to by using `tokenizer.convert_ids_to_tokens()`. Note that the tokenizer split some words such as \"skyddsskäl\" into \"skydds\" and \"##skäl\". This is made by the tokenizer to reduce the vocabulary size."
      ],
      "metadata": {
        "id": "2xnEkojAqYMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"KBLab/bert-base-swedish-cased\")\n",
        "input_ids = train_dataset[0][\"input_ids\"]"
      ],
      "metadata": {
        "id": "8RyNfe-yuMCL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_ids_to_tokens(input_ids[0])) # What tokens do the integer ids map to?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06yM_MkuyVj",
        "outputId": "6ee272cc-7fd8-403b-8be4-61eb3651dd89"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'För', 'många', 'av', 'våra', 'äldre', 'tonåringar', ',', 'inte', 'minst', 'på', 'landsbygden', ',', 'är', 'ep', '##a', '-', 'eller', 'A', '-', 'traktorer', 'en', 'mycket', 'viktig', 'del', 'av', 'uppväxten', '.', 'Intresset', 'är', 'en', 'sak', 'i', 'sig', 'men', 'för', 'många', 'är', 'det', 'även', 'ett', 'transportmedel', 'som', 'vilket', 'som', 'helst', 'annat', '.', 'Dessutom', 'ett', 'betydligt', 'tryggare', 'transportmedel', 'än', 'en', 'moped', 'där', 'du', 'sitter', 'helt', 'osk', '##ydda', '##d', '.', 'En', 'ep', '##a', '-', 'eller', 'A', '-', 'traktor', 'får', 'idag', 'köras', 'i', 'max', '30', 'km', '/', 'h', ',', 'och', 'således', 'har', 'den', 'lägre', 'max', '##hastighet', 'än', 'en', 'EU', '-', 'moped', 'som', 'får', 'gå', 'i', '45', 'km', '/', 'h', '.', 'Vanliga', 'jordbruks', '##trakt', '##orer', 'får', 'idag', 'köras', 'i', 'högst', '40', 'km', '/', 'h', '.', 'Reg', '##el', '##verket', 'spret', '##ar', 'när', 'man', 'som', 'osk', '##ydda', '##d', 'moped', '##ist', 'får', 'köra', 'fortare', 'än', 'när', 'du', 'sitter', 'inne', 'i', 'en', 'skyddande', 'kaross', 'i', 'en', 'ep', '##a', '-', 'eller', 'A', '-', 'traktor', '.', 'Därför', 'bör', 'regeringen', 'uppdat', '##era', 'och', 'modern', '##isera', 'de', 'föreskrifter', 'som', 'gäller', 'för', 'dessa', 'fordon', 'samt', 'utreda', 'om', 'eventuella', 'säkerhets', '##höj', '##ande', 'åtgärder', 'kan', 'krävas', 'med', 'höjd', 'hastighet', '##sg', '##rän', '##s', '.', 'Ett', 'beslut', 'i', 'denna', 'riktning', 'vore', 'en', 'frihets', '##reform', 'för', 'många', 'yngre', 'på', 'landsbygden', ',', 'inte', 'minst', 'där', 'kollektivtrafik', 'saknas', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a DataLoader to load batches\n",
        "\n",
        "Python is limited in terms of using multiple threads in the same process. A `DataLoader` object abstracts away the creation of multiple processes via `multiprocessing`, where each process independently loads batches of data. It ensures several batches are fetched in advance so that our main process doesn't have to pause and wait for a batch to be processed by the `MotionerDataset` before being able to proceed to pass it to the model. "
      ],
      "metadata": {
        "id": "3PTfFwY8waL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "train_dataset = MotionerDataset(df=df_train)\n",
        "valid_dataset = MotionerDataset(df=df_valid)\n",
        "\n",
        "# Colab free tier only has 2 CPUs\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=16, shuffle=True, num_workers=2\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, batch_size=16, shuffle=False, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "G-R3YvAazcQF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example output of our DataLoader\n",
        "\n",
        "Dataloaders are [iterables](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Iterables.html#Iterables), meaning we can iterate over them with `for` loops. If we want to inspect a batch manually without explicit looping, we need to use `iter()` and `next()`:"
      ],
      "metadata": {
        "id": "GcPkPsMnzyNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(f\"Dimensions of the batch: {batch['input_ids'].size()}\") # 16 obs of dim 1x512\n",
        "print(f\"Labels: {batch['label']}\")\n",
        "batch[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4flN4gP0uJW",
        "outputId": "8cb415f0-2da0-4586-be15-3a2563e060e0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of the batch: torch.Size([16, 1, 512])\n",
            "Labels: tensor([3, 5, 5, 1, 5, 5, 3, 5, 5, 6, 5, 5, 1, 3, 7, 7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[    2,   160,  1519,  ...,  2018,    59,     3]],\n",
              "\n",
              "        [[    2,   135,    61,  ...,     0,     0,     0]],\n",
              "\n",
              "        [[    2,   730,   621,  ...,     0,     0,     0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[    2,  7890, 39624,  ...,     0,     0,     0]],\n",
              "\n",
              "        [[    2,   609,   108,  ...,     0,     0,     0]],\n",
              "\n",
              "        [[    2,  1085,  1921,  ...,   200,  2128,     3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the Swedish BERT model for classification\n",
        "\n",
        "Let's load KB-BERT from the `transformers` library. We will be loading it for the specific purpose of performing document classification. At Huggingface, models with a classification head (a dense linear layer on top of the base transformer) are all named `XForSequenceClassification`, where `X` is the specific model implementation. In our case that's the BERT.  "
      ],
      "metadata": {
        "id": "U_Yr3LSl5lh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "# Note that we define the number of categories with `num_labels`.\n",
        "model = BertForSequenceClassification.from_pretrained(\"KBLab/bert-base-swedish-cased\", num_labels=9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtDMfQOK53Nj",
        "outputId": "475d7520-f01e-427c-8765-4113b7c3099b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at KBLab/bert-base-swedish-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look at the model and can identify the transformer layers. Just as in the original BERT we have 12 Transformer layers (called `BertLayer`) with self-attention (`BertSelfAttention`), here with dropout. Note that we can see the Q(uery), K(ey), and V(alue) parameters of the transformer layers. In the `BertSelfOutput` we can see the layer normalization of the output. \n",
        "\n",
        "The `BertIntermediate` part contain the feed-forward neural network och the transformer, here with a Gaussian Error Linear unit (GELu) activation function. We can also see the input (word) embedding layer with a vocabulary of size 50325 different word types, position embeddings, a layer normalization layer and dropout. The `BertPooler` layer is the classification head used for text classification with the BERT model."
      ],
      "metadata": {
        "id": "Z9hSr3YWBHka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpPOTXoFBGag",
        "outputId": "556cd2a8-156a-4566-d19e-0c1f728d84b3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50325, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we setup the use of a Graphical Processing Unit to speed up the training. This is strictly not nessecary, but make the training faster. We also check that the model is in training model."
      ],
      "metadata": {
        "id": "1qvk1LkvjAI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can make use of GPU if the if you have activated GPU in Colab\n",
        "# Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"We use:\", device)\n",
        "model.to(device) # Should the model run on CPU or GPU?\n",
        "model.train() # In train mode dropout is active, in eval mode dropout is inactivated\n",
        "# Boolean showing whether the model is in train mode or in eval model.\n",
        "print(\"The model is in training mode: \", model.training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuQ_RrO4A1aq",
        "outputId": "a3ec6eb1-f5f3-4100-a256-3bf067e63986"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We use: cuda\n",
            "The model is in training mode:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer, loss function and learning rate scheduler\n",
        "\n",
        "Next, we will be loading an optimizer, a loss function (cross entropy loss), and a learning rate scheduler that will vary the learning rate throughout the training process. \n",
        "\n",
        "* Optimizer: AdamW.\n",
        "* Loss: Cross-entropy loss\n",
        "* Learning rate scheduler: Sets a schedule for how the base learning rate should change throughout the training (rather than keeping a fixed learning rate throughout). \n",
        "\n",
        "> \"Adam can substantially benefit from a scheduled learning rate multiplier. The fact that Adam is an adaptive gradient algorithm and as such adapts the learning rate for each parameter does not rule out the possibility to substantially improve its performance by using a global learning rate multiplier, scheduled, e.g., by cosine annealing\" ([Loshcilov & Hutter, 2019](https://arxiv.org/abs/1711.05101))\n",
        "\n",
        "For our learning rate scheduler, we'll use the Kaggle-\"trendy\" [OneCycleLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#onecyclelr). \n",
        "\n",
        "Optimal learning rates are dataset and model dependent. If you set it manually, a normal process to figure out a reasonable rate is to train for a few minutes while keeping track of the loss. Then restart the training changing the loss by an order of magnitude or more, while comparing how quickly the loss drops. You may also try \"hyperparameter optimization\" tools that explores the optimal paramters for you. Though, these tools can tend to be fairly overkill for simple finetuning problems such as this one. "
      ],
      "metadata": {
        "id": "x_7HZDAoBPhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The total number of epochs\n",
        "nr_epochs=4\n",
        "\n",
        "# The optimizer we are going to use\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# The loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# The learning rate scheduler\n",
        "learning_rate_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-5,\n",
        "    epochs=nr_epochs,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "nAe6T_trEZ4W"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A learning rate scheduler change the learning rate over the training time. In fact, we can step through the scheduler and extract its learning rate values for each iteration even without training the model.  The total number of steps that the scheduler will generate learning rates for will be `nr_epochs * len(train_loader)`. \n",
        "\n",
        "Let's loop through all these values and extract the learning rate for each step of the scheduler. We can plot the results with `matplotlib` as follows."
      ],
      "metadata": {
        "id": "WVSDpuJkEy8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "\n",
        "iter = []\n",
        "learning_rates = []\n",
        "for i in range(nr_epochs * len(train_loader)):\n",
        "    optimizer.step()\n",
        "    learning_rates.append(learning_rate_scheduler.get_last_lr())\n",
        "    iter.append(i)\n",
        "    learning_rate_scheduler.step()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(iter, learning_rates)\n",
        "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "A5Fe2FeCAKaN",
        "outputId": "54c3d92a-0a0b-4703-9b69-1067b1f8f0d7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training/finetuning\n"
      ],
      "metadata": {
        "id": "v-JbXNYHpv7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently all parameters in the BERT model going to be trained. The `boolean` `param.requires_grad` indicates if the weight should be trained (`True`) or if it is freezed (`False`). Hence we can list the parameters to train as follows."
      ],
      "metadata": {
        "id": "fPPCRoBJny9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List parameters to train\n",
        "for name, param in model.named_parameters(): \n",
        "  if param.requires_grad: \n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjmfL4kcnzax",
        "outputId": "d609822c-3193-432f-dc5c-eafdb3bd5c04"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first step we will only train the classification head, that is the bert.pooler layer and the classifier."
      ],
      "metadata": {
        "id": "C8n0Z5dron_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We now just set some parameters to be trained\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.bert.pooler.dense.weight.requires_grad = True\n",
        "model.bert.pooler.dense.bias.requires_grad = True\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True\n",
        "\n",
        "# List parameters to train\n",
        "for name, param in model.named_parameters(): \n",
        "  if param.requires_grad: \n",
        "    print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGUblDYKpJsa",
        "outputId": "06615a12-3a4d-4a66-b39c-039046fa9fc5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now to the actual training of the model. Our approach will be to write a standard Pytorch training loop, where we iterate over the epochs and batches with `for` loops. The general structure for such a training loop is as follows:\n",
        "\n",
        "```python\n",
        "nr_epochs = 4\n",
        "\n",
        "for epoch in range(nr_epochs):\n",
        "  for i, batch in enumerate(train_loader):\n",
        "    # We set the gradients to zero\n",
        "    optim.zero_grad() \n",
        "\n",
        "    # Extract the input_ids, attention_mask and labels.\n",
        "    # Make sure they are on the right device before being passed to model.\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    # Compute the loss\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    loss = loss_function(outputs[\"logits\"], labels)\n",
        "\n",
        "    loss.backward() # Gradient update step, backward pass\n",
        "    optim.step() # Optimizer update step\n",
        "    scheduler.step() # Scheduler update step\n",
        "```"
      ],
      "metadata": {
        "id": "S6wa2R5b5JgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we stepped through our optimizer and scheduler above, we need to reinstantiate them once again:"
      ],
      "metadata": {
        "id": "1KixOPzNiSZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The total number of epochs\n",
        "nr_epochs=1\n",
        "\n",
        "# The optimizer we are going to use\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# The loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# The learning rate scheduler\n",
        "learning_rate_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optim,\n",
        "    max_lr=1e-5,\n",
        "    epochs=nr_epochs,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "rBlDU0VHH5i0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why would we prefer writing our own training loop as opposed to just using some framework providing cushy high level abstractions? As we'll see soon, the benefit is mainly that you have the freedom to customize, adapt and debug your code very easily and freely. \n",
        "\n",
        "* **Customization**: You don't need to understand the ins and outs of a framework, nor inspect its source code to implement, adapt and change things. \n",
        "* **Debugging**: Every parameter, every loss, every optimizer state, every scheduler state, every input and every output is available and easily inspectable for you. These things are generally hidden away from you when using higher level frameworks. \n",
        "\n",
        "For our actual training loop, we will add a few things. \n",
        "\n",
        "1. At certain intervals of iterations we would like to print our average loss during that interval. \n",
        "2. Every epoch we would like to print our accuracy, a confusion matrix, and some other useful metrics. \n",
        "\n",
        "In order to be fully transparent, I should state that in a typical work flow,  generally the training loop is developed first without having prediction code in place. Generally the process will include training the model for a while without doing evaluations and predictions (only tracking loss). At this stage is where the partly trained -- and unfinished -- model is used to write a proper prediction function with evaluation measures. This step is generally easier and less error prone to code once the model starts making predictions that are somewhat sensible. \n",
        "\n",
        "In this tutorial I will provide a prediction function immediately, but keep in mind that the figuring out of how to do basic prediction generally comes *after* having a model that no longer outputs random jibberish. "
      ],
      "metadata": {
        "id": "mWBSt4RgNSYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def predict(model, df_valid):\n",
        "    probs_list = []\n",
        "\n",
        "    # Ensure model is in eval mode before predicting (this ignores dropout layers)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(valid_loader)):\n",
        "            # .squeeze(dim=1) changes dims [16, 1, 512] ---> [16, 512]\n",
        "            input_ids = batch[\"input_ids\"].to(device).squeeze(dim=1)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            probs_list += torch.nn.functional.softmax(outputs[\"logits\"], dim=1)\n",
        "\n",
        "        preds = [torch.argmax(probs, dim=0).to(\"cpu\") for probs in probs_list]\n",
        "        df_valid[\"preds\"] = [int(pred) for pred in preds]\n",
        "        df_valid[\"probs\"] = [probs.to(\"cpu\").tolist() for probs in probs_list]\n",
        "\n",
        "    return df_valid\n"
      ],
      "metadata": {
        "id": "NmjuiuDjUKGq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the classification head (takes approx 8 minutes)\n",
        "\n",
        "One devious thing we have to look out for is that models expect input of a certain dimensionality. Sometimes the output of our dataset/dataloader might not conform to these expectations. In our case the dimensionality of a batch of `input_ids` comes out as $16\\times1\\times512$. We can think of it as $16$ observations of $1\\times512$ matrices. However, the row dimension $1$ of those matrices is redundant here. We might as well think of it as $16$ observations of $512$-length vectors. The model in fact expects a dimensionality of `(batch_size, input_length)` for each batch. \n",
        "\n",
        "A common operation for making this redundant $1$-dimensions disappear in Pytorch is the `.squeeze()` operation. Conversely, if we want to insert one of these dimensions (because a model for some reason expects it), we can use `.unsqueeze()`. \n",
        "\n",
        "In the code below you will see `batch[\"input_ids\"].to(device).squeeze(dim=1)`, where we transform `input_ids` from $16\\times1\\times512$ to $16\\times512$. The argument `dim` here refers to along which of the 3 axes `(batch_size, dummy_row, input_length)`: $16$, $1$ or $512$ that we want to perform the squeeze operation. The dimension axes start counting from $0$ (with $0$ being the `batch_size` dimension). \n",
        "\n"
      ],
      "metadata": {
        "id": "Wnks63axURqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "loss_logger = []\n",
        "iter_before_print = 50 # Iterations before printing avg loss\n",
        "\n",
        "for epoch in range(nr_epochs):\n",
        "    print(f\"epoch: {epoch + 1} started\")\n",
        "    running_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        # .squeeze(dim=1) changes dims [16, 1, 512] ---> [16, 512]\n",
        "        input_ids = batch[\"input_ids\"].to(device).squeeze(dim=1)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_function(outputs[\"logits\"], labels)\n",
        "        \n",
        "        # Collect losses to print running avg, and later plotting\n",
        "        running_loss += loss.item()\n",
        "        if i % iter_before_print == (iter_before_print - 1):\n",
        "            print(\n",
        "                (\n",
        "                f\" iter: {i+1}, loss: {running_loss/iter_before_print:.8f}, \"\n",
        "                f\"lr: {learning_rate_scheduler.get_last_lr()}\"\n",
        "                )\n",
        "            )\n",
        "            loss_logger.append({\"iter\": i + 1, \n",
        "                                \"loss\": running_loss / iter_before_print})\n",
        "            running_loss = 0\n",
        "\n",
        "        # Updates of gradients and learning rate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        learning_rate_scheduler.step()\n",
        "\n",
        "    # Prediction and evaluation metrics\n",
        "    df_res = predict(model=model, df_valid=df_valid)\n",
        "    accuracy = sum(df_res[\"label\"] == df_res[\"preds\"]) / len(df_res)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(\n",
        "        (\n",
        "            f\"\\033[94m Confusion Matrix: \\033[0m \\n\" # Blue colored text\n",
        "            f\"{pd.crosstab(df_res['label'], df_res['preds'], margins=True)}\"\n",
        "        )\n",
        "    )\n",
        "    print(metrics.classification_report(y_true=df_res[\"label\"], \n",
        "                                        y_pred=df_res[\"preds\"], \n",
        "                                        labels=list(label_mapping.values()),\n",
        "                                        target_names=label_mapping.keys(),\n",
        "                                        zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTK8oX9Vv4q",
        "outputId": "15315208-9baa-430c-cb2a-4c34f42f92ba"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 50/629 [00:31<06:21,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 50, loss: 2.03587908, lr: [9.007478022428104e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 100/629 [01:03<05:27,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 100, loss: 1.69961977, lr: [9.894399774299177e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 150/629 [01:33<04:55,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 150, loss: 1.68100195, lr: [9.427183223268402e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 200/629 [02:05<04:30,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 200, loss: 1.73729779, lr: [8.621285772655825e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 250/629 [02:36<03:54,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 250, loss: 1.66303688, lr: [7.538359107700797e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 300/629 [03:07<03:25,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 300, loss: 1.67203734, lr: [6.261247830820594e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 350/629 [03:39<02:55,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 350, loss: 1.60067401, lr: [4.887651795015111e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 400/629 [04:10<02:23,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 400, loss: 1.55303254, lr: [3.522652000827434e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 450/629 [04:41<01:52,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 450, loss: 1.50652671, lr: [2.2706718306606965e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 500/629 [05:12<01:20,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 500, loss: 1.54695426, lr: [1.2274885913153488e-06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 550/629 [05:44<00:49,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 550, loss: 1.57604424, lr: [4.7290648699900133e-07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 600/629 [06:15<00:18,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 600, loss: 1.53342501, lr: [6.465154519466958e-08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 629/629 [06:33<00:00,  1.60it/s]\n",
            "100%|██████████| 111/111 [01:06<00:00,  1.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4580281690140845\n",
            "\u001b[94m Confusion Matrix: \u001b[0m \n",
            "preds   1   3     5    7   All\n",
            "label                         \n",
            "0       0   0     0    1     1\n",
            "1      48  14   273   48   383\n",
            "2      12   4    35    8    59\n",
            "3       5  16   139   28   188\n",
            "4       4   2    47   15    68\n",
            "5      14  16   636   78   744\n",
            "6       1   2    50   23    76\n",
            "7       2   2   132  113   249\n",
            "8       0   0     4    3     7\n",
            "All    86  56  1316  317  1775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           V       0.00      0.00      0.00         1\n",
            "           S       0.56      0.13      0.20       383\n",
            "          MP       0.00      0.00      0.00        59\n",
            "           C       0.29      0.09      0.13       188\n",
            "           L       0.00      0.00      0.00        68\n",
            "           M       0.48      0.85      0.62       744\n",
            "          KD       0.00      0.00      0.00        76\n",
            "          SD       0.36      0.45      0.40       249\n",
            " independent       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.46      1775\n",
            "   macro avg       0.19      0.17      0.15      1775\n",
            "weighted avg       0.40      0.46      0.37      1775\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "How did the model perform on our evaluation dataset? It seems the model managed to to predict the correct party for roughly $46\\%$ of the parliamentary motions correctly. Although the data is unbalanced and the macro average indicate that we can improve. "
      ],
      "metadata": {
        "id": "DqcNXlDS8_zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    metrics.classification_report(\n",
        "        df_res[\"label\"], \n",
        "        df_res[\"preds\"], \n",
        "        labels=list(label_mapping.values()), \n",
        "        target_names=label_mapping.keys(),\n",
        "        zero_division=0\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH4iVRGsaTzG",
        "outputId": "3dfbb99f-7a58-41bd-b323-45ffc1462f52"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           V       0.00      0.00      0.00         1\n",
            "           S       0.56      0.13      0.20       383\n",
            "          MP       0.00      0.00      0.00        59\n",
            "           C       0.29      0.09      0.13       188\n",
            "           L       0.00      0.00      0.00        68\n",
            "           M       0.48      0.85      0.62       744\n",
            "          KD       0.00      0.00      0.00        76\n",
            "          SD       0.36      0.45      0.40       249\n",
            " independent       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.46      1775\n",
            "   macro avg       0.19      0.17      0.15      1775\n",
            "weighted avg       0.40      0.46      0.37      1775\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "YWGSSf4Aw_6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test our model on recent parliamentary motions\n",
        "\n",
        "We can test our model on texts from recently submitted parliamentary motions, which are neither part of the train nor the validation set. "
      ],
      "metadata": {
        "id": "YiUpch6hVfUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parliamentary motion from Miljöpartiet: https://www.riksdagen.se/sv/dokument-lagar/dokument/motion/stoppa-handeln-med-utrotningshotade-djur_HA022280\n",
        "motions_text = \"\"\"\n",
        "Handeln med hotade arter är världens fjärde största illegala handel, och omsätter ofantliga summor som göder kriminella nätverk. \n",
        "Forskare har länge varnat om att allt fler virus riskerar att spridas från djur till människor. \n",
        "Utbrottet av Coronaviruset Covid-19 har återigen satt strålkastarljuset på kopplingen mellan djurmarknader och sjukdomar. \n",
        "En anledning till att risken för virusspridning ökar på marknaderna är att det är ohygieniska förhållanden med en stor blandning av olika djurarter, ofta stressade – som aldrig skulle träffas naturligt i det vilda. Olika virus kan då hoppa från en djurart till en annan och sedan vidare till människan. \n",
        "På den internationella marknaden säljs varje år flera miljoner vildfångade fåglar, tiotusentals apor och ett oräkneligt antal andra djur och växter år på den internationella marknaden. Djuren säljs som exotiska husdjur, eller så används deras pälsar och skin inom klädindustrin. \n",
        "Delar från skelett, horn och betar används som ingredienser i naturmediciner och mat, till smycken och prydnadsföremål. Den stora efterfrågan på elfenben bidrar till allt för stor jakt på världens elefanter. Även världens noshörningsarter hotas av tjuvjakt och illegal handel.\n",
        "\"\"\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = tokenizer(\n",
        "        motions_text, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(outputs[\"logits\"], dim=1)\n",
        "    preds = torch.argmax(probs).to(\"cpu\")\n",
        "\n",
        "print(probs)\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "hsOqhp7LV110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e80fa9a-4efb-42dd-826b-c8c9f54a0a40"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.4263e-05, 2.0303e-01, 3.4401e-02, 7.1131e-02, 9.6352e-02, 4.3302e-01,\n",
            "         2.0872e-02, 1.4104e-01, 9.7988e-05]], device='cuda:0')\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authors\n",
        "\n",
        "* Faton Rekathati (faton.rekathati@kb.se)\n",
        "* Måns Magnusson (mans.magnusson@statistik.uu.se)\n"
      ],
      "metadata": {
        "id": "hUvDR5_mgNZ7"
      }
    }
  ]
}
